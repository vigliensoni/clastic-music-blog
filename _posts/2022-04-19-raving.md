---
layout: post
current: post
cover:  assets/images/rave.png
navigation: True
title: RAVE modelling
date: 2022-04-10 5:34:00
tags: [RAVE]
class: post-template
subclass: 'post'
author: gabriel
---

### RAVE
- Training consists of two steps, and the first training step has two stages:
  - Representational learning: VAE training 
  - Adversarial fine tuning: 
  - Latent representation compactness: PRIOR training

- Finished a full model creation last week. 
- The dataset consists of a series of recordings and interviews that the people I'm working with in Mallorca use for their events (4.5 hours)
  - Poetry read by friends
  - Conversations and historical recording s with First Nations from South America
  - Audio documents about space and time
  
- With the default values of the repo (i.e., number of steps, latent space dimensions, fidelity) 
  - RAVE took 4.5 days to be trained (1st: 1d10h, 3nd: 3d)
  - PRIOR took 1 day to be trained

- Tested the model with the MaxMSP object, was able to use it inside M4L and prime the model with audio coming from the DAW, while at the same time exploring the latent spaces.

 <audio controls>
  <source src="assets/sounds/AS-01.mp3" type="audio/mpeg">
Your browser does not support the audio element.
</audio> 

- A few glitches here and there due to computer processing. Much better in second try. 

<audio controls>
  <source src="assets/sounds/AS-02.mp3" type="audio/mpeg">
Your browser does not support the audio element.
</audio> 


- **New training**
  - 7 models, music files of qualities
    - Acoustic harmonic (33h)
    - Acoustic percussive (17h)
    - Electronic harmonic (16h)
    - Electronic percussive (15h)
    - Caterina Barbieri (6h)
    - Vigliensoni (6h)
  - Some changes with the previous full training
    - KL divergence now fixed (not variable)
    - Number of max steps now match the experiments of the paper (i.e., 3M steps)


### Data augmentation

RAVE provides a command line method for data augmentation

```
resample --sr 48000 --augment
resample --sr 48000 --input 06-VIGLIENSONI-AUG --output 06-VIGLIENSONI-AUG/out_48000 --augment
```

The method converts all audio file types to wav, converts them to a mono file, and resamples them to the desired sample rate. 

It also comes with a method for measuring the duration of all audio files in a folder

```
duration
```

I applied data augmentation to the AS dataset, which consists mostly in spoken voice, and got the following results:

```
cd the-original-folder
duration

found 4 .wav files
total duration: 0h 12m 52s

cd the-augmented-folder
duration

Found 814 .wav files
total duration: 10h 31m 12s
```

- [ ] I'm now actually submitting two jobs with the augmented data for the datasets AS and VIGLIENSONI. I'm also passing the value 16 to the cropped-latent-size flag to see if the dimensionality is reduced.

- [ ] I'm also checking the results of the augmentation in my own dataset

#### QUESTIONS 

What are the following terms:
```
capacity : capability to learn some arbitrary function which can map the data to an index. there's capacity for the encoder and the decoder.
no-latency : related to PQMF (pseudo-quadrature mirror filters), sub-band coding for neural vocoders
cropped-latent-size : is this related to setting up a fixed latent space size instead of learning one?
```

